{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "# scatter plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 解决matplotlib以及seaborn中文字方块的问题\n",
    "from pylab import mpl\n",
    "import seaborn as sns\n",
    "\n",
    "# 3D plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "\n",
    "# 分词方程： seperater\n",
    "import jieba\n",
    "import re\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       10216\n",
       "unique       9658\n",
       "top       子宫楔形切除术\n",
       "freq            3\n",
       "Name: detail_name, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd9v2 = pd.read_csv(r'~\\Desktop\\icd9_cm3\\icd9_cm3.csv',encoding = 'gb18030')\n",
    "icd9v3 = icd9v2[icd9v2['detail_name'] != '(null)']\n",
    "icd9v3 = icd9v3.reset_index(drop=True)\n",
    "icd9v3['detail_name'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作字典\n",
    "- 目标：合并原先被错误分词的词语，去掉没有意义的高频次\n",
    "- 资源来源\n",
    "    - 北京大学云中心的“提交-字典数据”\n",
    "    - [王晔](wangye@wondersgroup.com)提供的“组织、部位与治疗方式.xlsx与新词探查工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已知字典导入\n",
    "body_part = pd.read_excel(r'C:\\Users\\MYTh_\\Desktop\\组织、部位与治疗方式.xlsx',encoding = 'gb18030')\n",
    "body_part2 = pd.read_excel(r'C:\\Users\\MYTh_\\Desktop\\提交-词典数据.xlsx',encoding = 'gb18030',sheetname = '手术及治疗')\n",
    "\n",
    "# 未知字典制作：通过正反向最大词向量在原数据中发现新词\n",
    "fs = pd.read_csv(r'~\\Desktop\\1.csv',encoding = 'utf-8', header = [-1])\n",
    "bs = pd.read_csv(r'~\\Desktop\\2.csv',encoding = 'utf-8', header = [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsbox = []\n",
    "\n",
    "for word in fs[0]:\n",
    "    temp = word.split(' ')\n",
    "    for i in range(len(temp)):\n",
    "#        if len(temp[i]) == 1 or len(temp[i]) > 6:   #只选取字符长度 < = 5 的术式名称\n",
    "#            continue\n",
    "#        else:\n",
    "            fsbox.append(temp[i])\n",
    "\n",
    "bsbox = []\n",
    "\n",
    "for word in bs[0]:\n",
    "    temp = word.split(' ')\n",
    "    for i in range(len(temp)):\n",
    "        bsbox.append(temp[i])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#字典建立\n",
    "dictionary = []\n",
    "\n",
    "#导入第一本字典\n",
    "for i in range(len(body_part.columns)):\n",
    "    temp = body_part[body_part.columns[i]].dropna()    \n",
    "    for j in range(len(temp)):\n",
    "        dictionary.append(temp[j])\n",
    "\n",
    "#导入第二本字典\n",
    "for i in range(len(body_part2['词语'])):\n",
    "    if len(str(body_part2['词语'][i])) <  5:\n",
    "        dictionary.append(len(body_part2['词语'][i]))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# 导入正向查找字典\n",
    "for word in fsbox:\n",
    "    dictionary.append(word)\n",
    "    \n",
    "# 导入反向查找字典\n",
    "for word in bsbox:\n",
    "    dictionary.append(word)\n",
    "\n",
    "np.savetxt(r'C:\\Users\\MYTh_\\Desktop\\wyfc_2015\\dictionary.txt', dictionary, fmt='%s',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同结构的字典，为了后续的分析而建立\n",
    "list_dic = []\n",
    "\n",
    "for word in dictionary:\n",
    "    list_dic.append(re.findall('[\\u4E00-\\u9FA5A-Za-z]+',str(word)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到并保存去掉不需要字符且没有被分割的手术名称\n",
    "\n",
    "for i in range(len(icd9v3.detail_name)):      \n",
    "    hans = re.findall('[\\u4E00-\\u9FA5A-Za-z]+',icd9v3.detail_name[i])\n",
    "    combine = ''.join(hans)\n",
    "    icd9v3.loc[i, 'clean_dn'] = combine\n",
    "\n",
    "np.savetxt(r'C:\\Users\\MYTh_\\Desktop\\wyfc_2015\\test.txt', icd9v3.clean_dn, fmt='%s',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 分词方程： seperater\n",
    "\n",
    "for word in dic:\n",
    "    jieba.suggest_freq(word, True)   #导入字典\n",
    "\n",
    "def seperater(param):\n",
    "        \n",
    "    hans_before = \"\".join(re.findall('[\\u4E00-\\u9FA5A-Za-z]+',param))\n",
    "    hans_after = re.sub(u\"(术+)|(的+)|(病+)\",\"\",hans_before)\n",
    "    after_seg = ''.join(hans_after)\n",
    "    \n",
    "    seg_list = jieba.cut(after_seg, cut_all=False)\n",
    "    temp = \" \".join(seg_list)\n",
    "\n",
    "    return temp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 执行分词并保存\n",
    "for i in range(len(icd9v3)):\n",
    "    icd9v3.loc[i, 'tokens'] = seperater(icd9v3.detail_name[i])\n",
    "    \n",
    "np.savetxt(r'C:\\Users\\MYTh_\\Desktop\\icd9_cm3\\segment.txt', icd9v3.tokens.values, fmt='%s',encoding = 'utf-8')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征词提取\n",
    "一般情况下，名词和动词比其他词性的词重要。另外，词语包括的字数越多，包含的信息量越大。论文中定义了一种基于词性和词长度的特征词权重计算公式，即\n",
    "$Weight{w_{id}} = \\lambda Weight_{pos}(w_{id})+(1-\\lambda)Weight_{len}(w_{id})$\n",
    "                \n",
    "式中：$Weight(w_{id})$表示词语$w_i$在文本$d$中的权重，$Weight_{pos}(w_{id})$表示$$w_i在文本d中的词性权重，$Weight_{len}(w_{id})$表示$w_i$在文本d中的长度权重，$\\lambda$和$(1-\\lambda)$为加权系数，$\\lambda$取经验值0.6。$Weight_{pos}(w_{id})$和$Weight_{len}(w_{id})$的具体计算公式为\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 权重分词 \n",
    "posdf = pd.DataFrame()\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "for i in range(len(icd9v3.tokens)):\n",
    "    words = pseg.cut(icd9v3.tokens[i])\n",
    "    for word1,j in zip(words,range(33)):\n",
    "        posdf.loc[i,j] = '%s'%word1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "引导下/x\n"
     ]
    }
   ],
   "source": [
    "jieba.suggest_freq('引导下', True)\n",
    "words = pseg.cut('引导下')\n",
    "for word in words:\n",
    "    print ('%s'  % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_pos = posdf[[0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,31,32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词向量模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYTh_\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "# 词向量训练\n",
    "model = Word2Vec(sentences = LineSentence(r'~\\Desktop\\icd9_cm3\\segment.txt'),\n",
    "                 size = 500, \n",
    "                 min_count = 1,\n",
    "                 sg=1)  \n",
    "model.save('op_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 高频词查找\n",
    "\n",
    "freq_count = []\n",
    "\n",
    "for w in model.wv.vocab:\n",
    "        freq_count.append([w,model.wv.vocab[w].count])\n",
    "token_freq = pd.DataFrame(data = freq_count, columns = ['token_name','frequency'])\n",
    "np.savetxt(r'C:\\Users\\MYTh_\\Desktop\\icd9_cm3\\high_freq.txt', token_freq.sort_values(by = [\"frequency\"],ascending = False), fmt='%s',encoding = 'utf-8')\n",
    "token_freq.sort_values(by = [\"frequency\"],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_writer = pd.ExcelWriter(r'C:\\Users\\MYTh_\\Desktop\\icd9_cm3\\high_freq.xlsx')\n",
    "token_freq.sort_values(by = [\"frequency\"],ascending = False).to_excel(hf_writer,'Sheet1')\n",
    "hf_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYTh_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# 训练范围：全部词\n",
    "# 求出每个手术名称的词向量均值\n",
    "vector_list = []\n",
    "\n",
    "for i in range(len(icd9v3.tokens)):\n",
    "    vector_list.append(np.mean(model[list(icd9v3.tokens[i].split(' '))], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYTh_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 训练范围：匹配词\n",
    "# 求出每个手术名称的词向量均值\n",
    "vector_list = []\n",
    "\n",
    "for i in range(len(matched_tokens)):\n",
    "    vector_list.append(np.mean(model[list(matched_tokens[i].split(' '))], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k均值聚类\n",
    "# 聚类数量：默认4000；如果需要测试匹配词需要调低\n",
    "kmeans = cluster.KMeans(n_clusters = 4000 ,max_iter = 2000)\n",
    "kmeans.fit(vector_list)\n",
    "labels= kmeans.predict(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 标记所有手术名称并保存\n",
    "icd9v3[\"label\"] = labels\n",
    "icd9v3_sorted = icd9v3.sort_values(by = ['label'], ascending = (True))\n",
    "labeled_icd9 = icd9v3_sorted[['detail_code','detail_name','label']]\n",
    "writer = pd.ExcelWriter(r'C:\\Users\\MYTh_\\Desktop\\icd9_cm3\\labeled_ICD9-CM3_test.xlsx')\n",
    "labeled_icd9.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配成功的分词有：7546\n",
      "匹配失败的分词有：2670\n"
     ]
    }
   ],
   "source": [
    "print(\"匹配成功的分词有：\" + str(len(matched_tokens)))\n",
    "print(\"匹配失败的分词有：\" + str(len(unmatched_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试代码\n",
    "1. 匹配词分类查看\n",
    "2. 匹配词计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_names</th>\n",
       "      <th>label</th>\n",
       "      <th>detail_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>女性 去势 术</td>\n",
       "      <td>0</td>\n",
       "      <td>女性去势术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>咽鼓管 通气 术</td>\n",
       "      <td>0</td>\n",
       "      <td>咽鼓管通气术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>咽鼓管 通气 术</td>\n",
       "      <td>0</td>\n",
       "      <td>咽鼓管通气术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>无痛 刮宫 术</td>\n",
       "      <td>0</td>\n",
       "      <td>无痛刮宫术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>下颌 磨削 术</td>\n",
       "      <td>0</td>\n",
       "      <td>下颌磨削术</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sp_names  label detail_name\n",
       "4692   女性 去势 术      0       女性去势术\n",
       "1248  咽鼓管 通气 术      0      咽鼓管通气术\n",
       "1250  咽鼓管 通气 术      0      咽鼓管通气术\n",
       "4858   无痛 刮宫 术      0       无痛刮宫术\n",
       "5166   下颌 磨削 术      0       下颌磨削术"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 匹配词单独分类文件保存\n",
    "\n",
    "matched = pd.DataFrame()\n",
    "matched['sp_names'] = matched_tokens\n",
    "matched[\"label\"] = labels\n",
    "\n",
    "matched = matched.sort_values(by = ['label'], ascending = (True))\n",
    "\n",
    "for i in range(len(matched)):\n",
    "    matched.loc[i,'detail_name'] = \"\".join(matched.sp_names[i].split(' '))\n",
    "\n",
    "writer = pd.ExcelWriter(r'C:\\Users\\MYTh_\\Desktop\\icd9_cm3\\match-labeled_ICD9-CM3_test.xlsx')\n",
    "matched.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匹配/不匹配词计数\n",
    "\n",
    "matched_tokens = []\n",
    "unmatched_tokens= []\n",
    "\n",
    "for i in range(len(icd9v3.tokens)):\n",
    "    temp = icd9v3.tokens[i].split(' ')\n",
    "    for word in temp:\n",
    "        if word in dictionary:\n",
    "            matched_tokens.append(icd9v3.tokens[i])\n",
    "            break\n",
    "        else:\n",
    "            unmatched_tokens.append(icd9v3.tokens[i])\n",
    "            break  \n",
    "            \n",
    "print(\"匹配成功的分词有：\" + str(len(matched_tokens)))\n",
    "print(\"匹配失败的分词有：\" + str(len(unmatched_tokens)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
