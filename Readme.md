
### ICD-9-CM-3 介绍

- ICD-9-CM的全称为**国际疾病分类临床修改版，第九次修订版**
- 其中ICD-9-CM的第1卷和第2卷用于诊断代码
- 第3卷，即ICD-9-CM-3，用于对医疗程序进行分类以用于计费目的的程序代码系统


### 主要目标

- **在不依靠详细手术编码，即表中deail_code，的情况下对ICD9-CM3的手术名称进行聚类**
- 聚类后可以对绝大多数的类别进行描述，描述的内容对该类下的所有内容具有唯一性
  - **唯一性**指的是， 通过描述可以对该类下的手术名称进行识别。同时，该描述不可适用于其他类。

### 实现方法及步骤

1. 数据清理
2. **分词**
3. **词向量模型训练**
4. 短文本（手术名称）平均向量计算
5. **文本聚类**
6. 聚类效果评估

### 数据清理

- 去除详细手术名称(detail_name)中不需要或是无意义的词
  - **(null)** 表示该手术没有详细代码
  - **[ ] 方括号**中的内容为同义词、替换词或解释语
  - **( )圆括号**用以表示补充词
  - 部分严重影响聚类结果且无意义的高频词，如“术”，“性”等
- 分词
  - [jieba](https://github.com/Embedding/Chinese-Word-Vectors/tree/master/testsets)
  - ~~CoreNLP~~
  - ~~SnowNLP~~

### 词向量训练

- 为什么使用`Word2Vec`？
  - **`Word2vec` 本质上是一种把词语从 `one-hot encoder` 的形式，表示成向量形式的降维操作**，通过最终得到的向量取均值完成聚类
  - 需要区分手术名称中的语义关系
- 无法使用已经[训练好的词向量](https://github.com/Embedding/Chinese-Word-Vectors)的原因是：
  - 主要训练对象是维基百科和报纸上的文本，对医学类词语的训练结果不准确


### 训练过程

```python
model = Word2Vec(sentences=LineSentence('~/segment.txt'),
                 size = 500, 
                 min_count = 1,
                 sg=1) 
```

- **训练维度选择**：生成的词向量从100维到1000维（间隔50维）
- **评估方法**：提取同一个关键词，如“治疗”，比较起相似度最大的十个词语
- 当训练维度 > 500之后，观察最相似的10个词语基本开始停止变化，因此取500维作为最终训练维度


### 短文本向量计算

- 常用计算文本向量的方法有
  - 均值Word2Vec：这里使用的方法
  - ~~Sent2Vec~~
    - 数据集较小，不适用
  - ~~TF-IDF~~
    - 运行效率异常缓慢，且结果没有显著提高

### 文本聚类

- 使用`K-means`实现文本聚类

```python
kmeans = cluster.KMeans(n_clusters = 5000,max_iter = 2000)
kmeans.fit(vector_list)
```

- 生成标签并标记原数据

```python
labels= kmeans.predict(vector_list)
icd9v3["label"] = labels
icd9v3_sorted = icd9v3.sort_values(by = ['label'], 
				   ascending = (True))
```
### 完成数据（1）

- 【普通】完成了分类，但与手术编码的分类完全一致

  ![](https://i.loli.net/2018/11/17/5befb42562c31.png)

- 【最完美】没有依靠手术编码，完成主要目标

  ![](https://i.loli.net/2018/11/17/5befb4e16db33.png)


### 完成数据（2）

- 【尚可接受】完成分类，但未必具有足够医学意义。目前，这样的结果是==普遍情况==

  ![](https://i.loli.net/2018/11/17/5befb5b69fde0.png)

- 【灾难】毫无逻辑，主要原因为大量低频词的组合

  ![](https://i.loli.net/2018/11/17/5befb68300d8c.png)


### 目前的困难

- 无法获得高质量的语料
- 分词后会出现部分无法被舍弃的高频次
  - 如：“切除”、“切开”、“其他”等
- 高频词取舍
  1. ==无法判断分类后的合理性与准确性==

1. ~~因为词频太低导致的分类错误~~

- 算法优化
- ~~分类后依然有5000个类别，相比原先的10316只缩小的一倍~~


### 未来优化方案(11/17更新)

1. 需要专业的医学书籍作为语料
2. ~~医学方面的停词表的建立~~ 【不完美完成】
3. ~~加入其他参数，如：手术费用，每年实施这个手术的人数等~~ 【不需要】
4. **对医学术语的分词需要专业人员的指导**

